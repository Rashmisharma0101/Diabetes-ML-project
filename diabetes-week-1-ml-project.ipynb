{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1400440,"sourceType":"datasetVersion","datasetId":818300}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#  \"Understanding Risk Patterns in Diabetes Patients\"","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.323813Z","iopub.execute_input":"2025-07-26T22:21:13.324356Z","iopub.status.idle":"2025-07-26T22:21:13.337487Z","shell.execute_reply.started":"2025-07-26T22:21:13.324319Z","shell.execute_reply":"2025-07-26T22:21:13.335981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\n\n# Ignore all warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.339590Z","iopub.execute_input":"2025-07-26T22:21:13.340040Z","iopub.status.idle":"2025-07-26T22:21:13.363684Z","shell.execute_reply.started":"2025-07-26T22:21:13.340005Z","shell.execute_reply":"2025-07-26T22:21:13.362145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/diabetes-data-set/diabetes.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.364860Z","iopub.execute_input":"2025-07-26T22:21:13.365253Z","iopub.status.idle":"2025-07-26T22:21:13.392126Z","shell.execute_reply.started":"2025-07-26T22:21:13.365226Z","shell.execute_reply":"2025-07-26T22:21:13.390932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = df['Outcome']\nX = df.drop('Outcome', axis =1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.394637Z","iopub.execute_input":"2025-07-26T22:21:13.395049Z","iopub.status.idle":"2025-07-26T22:21:13.402382Z","shell.execute_reply.started":"2025-07-26T22:21:13.395024Z","shell.execute_reply":"2025-07-26T22:21:13.400723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.403858Z","iopub.execute_input":"2025-07-26T22:21:13.404619Z","iopub.status.idle":"2025-07-26T22:21:13.424913Z","shell.execute_reply.started":"2025-07-26T22:21:13.404582Z","shell.execute_reply":"2025-07-26T22:21:13.423554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.425953Z","iopub.execute_input":"2025-07-26T22:21:13.426243Z","iopub.status.idle":"2025-07-26T22:21:13.445193Z","shell.execute_reply.started":"2025-07-26T22:21:13.426221Z","shell.execute_reply":"2025-07-26T22:21:13.443950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check Nulls\n\nX.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.446125Z","iopub.execute_input":"2025-07-26T22:21:13.446432Z","iopub.status.idle":"2025-07-26T22:21:13.464704Z","shell.execute_reply.started":"2025-07-26T22:21:13.446401Z","shell.execute_reply":"2025-07-26T22:21:13.463449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.465853Z","iopub.execute_input":"2025-07-26T22:21:13.467310Z","iopub.status.idle":"2025-07-26T22:21:13.492619Z","shell.execute_reply.started":"2025-07-26T22:21:13.467283Z","shell.execute_reply":"2025-07-26T22:21:13.491442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.493676Z","iopub.execute_input":"2025-07-26T22:21:13.494075Z","iopub.status.idle":"2025-07-26T22:21:13.517692Z","shell.execute_reply.started":"2025-07-26T22:21:13.494044Z","shell.execute_reply":"2025-07-26T22:21:13.516682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check outlier\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfor col in X.columns:\n    plt.figure(figsize = (5,6))\n    sns.boxplot(X[col])\n    plt.title(col)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:13.539219Z","iopub.execute_input":"2025-07-26T22:21:13.539758Z","iopub.status.idle":"2025-07-26T22:21:14.669277Z","shell.execute_reply.started":"2025-07-26T22:21:13.539725Z","shell.execute_reply":"2025-07-26T22:21:14.668331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# almost all fetaures have outliers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.670851Z","iopub.execute_input":"2025-07-26T22:21:14.671205Z","iopub.status.idle":"2025-07-26T22:21:14.675850Z","shell.execute_reply.started":"2025-07-26T22:21:14.671176Z","shell.execute_reply":"2025-07-26T22:21:14.674678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.676989Z","iopub.execute_input":"2025-07-26T22:21:14.677414Z","iopub.status.idle":"2025-07-26T22:21:14.701107Z","shell.execute_reply.started":"2025-07-26T22:21:14.677375Z","shell.execute_reply":"2025-07-26T22:21:14.700142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# all are integer or float columns , so no processing required in that arena","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.703293Z","iopub.execute_input":"2025-07-26T22:21:14.703554Z","iopub.status.idle":"2025-07-26T22:21:14.718210Z","shell.execute_reply.started":"2025-07-26T22:21:14.703533Z","shell.execute_reply":"2025-07-26T22:21:14.716967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# about OUTLIERS!!  and scaling features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.719338Z","iopub.execute_input":"2025-07-26T22:21:14.719615Z","iopub.status.idle":"2025-07-26T22:21:14.737100Z","shell.execute_reply.started":"2025-07-26T22:21:14.719594Z","shell.execute_reply":"2025-07-26T22:21:14.735983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Droppping rows with outliers is not dropping too may  rows","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.739324Z","iopub.execute_input":"2025-07-26T22:21:14.739666Z","iopub.status.idle":"2025-07-26T22:21:14.765512Z","shell.execute_reply.started":"2025-07-26T22:21:14.739642Z","shell.execute_reply":"2025-07-26T22:21:14.764253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Xy = pd.concat([X, y], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.766807Z","iopub.execute_input":"2025-07-26T22:21:14.767208Z","iopub.status.idle":"2025-07-26T22:21:14.788473Z","shell.execute_reply.started":"2025-07-26T22:21:14.767157Z","shell.execute_reply":"2025-07-26T22:21:14.787381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask = pd.Series(True, index=Xy.index)\nfor col in Xy.columns:\n    Q1 = Xy[col].quantile(0.25)\n    Q3 = Xy[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower = Q1 - 1.5 * IQR\n    upper = Q3 + 1.5 * IQR\n    mask &= (Xy[col] >= lower) & (Xy[col] <= upper)\n\nXy = Xy[mask]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.789516Z","iopub.execute_input":"2025-07-26T22:21:14.789838Z","iopub.status.idle":"2025-07-26T22:21:14.829270Z","shell.execute_reply.started":"2025-07-26T22:21:14.789809Z","shell.execute_reply":"2025-07-26T22:21:14.828019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Xy.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.830578Z","iopub.execute_input":"2025-07-26T22:21:14.830926Z","iopub.status.idle":"2025-07-26T22:21:14.837727Z","shell.execute_reply.started":"2025-07-26T22:21:14.830894Z","shell.execute_reply":"2025-07-26T22:21:14.836345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = Xy.drop('Outcome', axis=1)\ny = Xy['Outcome']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.840901Z","iopub.execute_input":"2025-07-26T22:21:14.841458Z","iopub.status.idle":"2025-07-26T22:21:14.866581Z","shell.execute_reply.started":"2025-07-26T22:21:14.841431Z","shell.execute_reply":"2025-07-26T22:21:14.865579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sacle the data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.867522Z","iopub.execute_input":"2025-07-26T22:21:14.867772Z","iopub.status.idle":"2025-07-26T22:21:14.896816Z","shell.execute_reply.started":"2025-07-26T22:21:14.867752Z","shell.execute_reply":"2025-07-26T22:21:14.895571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in X.columns:\n    plt.figure(figsize = (5,6))\n    sns.histplot(X[col])\n    plt.title(col)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:14.897661Z","iopub.execute_input":"2025-07-26T22:21:14.898119Z","iopub.status.idle":"2025-07-26T22:21:17.386125Z","shell.execute_reply.started":"2025-07-26T22:21:14.898088Z","shell.execute_reply":"2025-07-26T22:21:17.385107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inspect Skin thickness and Insulin\n\nprint(X['SkinThickness'].value_counts())\n\nprint(X['Insulin'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.387146Z","iopub.execute_input":"2025-07-26T22:21:17.387415Z","iopub.status.idle":"2025-07-26T22:21:17.397011Z","shell.execute_reply.started":"2025-07-26T22:21:17.387394Z","shell.execute_reply":"2025-07-26T22:21:17.395908Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# skin thickness / Insulin have large numbe of 0s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.398081Z","iopub.execute_input":"2025-07-26T22:21:17.399110Z","iopub.status.idle":"2025-07-26T22:21:17.416504Z","shell.execute_reply.started":"2025-07-26T22:21:17.399074Z","shell.execute_reply":"2025-07-26T22:21:17.415117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  as 0 skin is meaningless, replace 0 with nans\n\nX['SkinThickness'] = X['SkinThickness'].replace(0, np.nan)\nX['Insulin'] = X['Insulin'].replace(0, np.nan)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.417635Z","iopub.execute_input":"2025-07-26T22:21:17.418000Z","iopub.status.idle":"2025-07-26T22:21:17.440210Z","shell.execute_reply.started":"2025-07-26T22:21:17.417970Z","shell.execute_reply":"2025-07-26T22:21:17.438917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Impute missing values for these columns\n# using KNNimputer\n\nfrom sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors = 5)\nX[['SkinThickness', 'Insulin']] = imputer.fit_transform(X[['SkinThickness', 'Insulin']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.441386Z","iopub.execute_input":"2025-07-26T22:21:17.441731Z","iopub.status.idle":"2025-07-26T22:21:17.485417Z","shell.execute_reply.started":"2025-07-26T22:21:17.441703Z","shell.execute_reply":"2025-07-26T22:21:17.484322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pregnancies and age\n# Check skewnewss\n\nX[['Pregnancies', 'Age']].skew()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.486478Z","iopub.execute_input":"2025-07-26T22:21:17.486779Z","iopub.status.idle":"2025-07-26T22:21:17.497662Z","shell.execute_reply.started":"2025-07-26T22:21:17.486756Z","shell.execute_reply":"2025-07-26T22:21:17.496656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# apply log1px transform\n\nX['Pregnancies'] = np.log1p(X['Pregnancies'])\nX['Age'] = np.log1p(X['Age'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.498676Z","iopub.execute_input":"2025-07-26T22:21:17.498995Z","iopub.status.idle":"2025-07-26T22:21:17.530095Z","shell.execute_reply.started":"2025-07-26T22:21:17.498966Z","shell.execute_reply":"2025-07-26T22:21:17.528938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# now apply scaling\n\nfrom sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\nX_scaled = scaler.fit_transform(X)\nX = pd.DataFrame(X_scaled, columns  = X.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.531540Z","iopub.execute_input":"2025-07-26T22:21:17.531946Z","iopub.status.idle":"2025-07-26T22:21:17.555770Z","shell.execute_reply.started":"2025-07-26T22:21:17.531916Z","shell.execute_reply":"2025-07-26T22:21:17.554746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.557062Z","iopub.execute_input":"2025-07-26T22:21:17.557721Z","iopub.status.idle":"2025-07-26T22:21:17.574677Z","shell.execute_reply.started":"2025-07-26T22:21:17.557679Z","shell.execute_reply":"2025-07-26T22:21:17.573542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Applying Random forest Classifier on the data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.575824Z","iopub.execute_input":"2025-07-26T22:21:17.576244Z","iopub.status.idle":"2025-07-26T22:21:17.593547Z","shell.execute_reply.started":"2025-07-26T22:21:17.576212Z","shell.execute_reply":"2025-07-26T22:21:17.592071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Random forest classifier + recall\nfrom  sklearn.model_selection  import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nimport random\nfrom scipy.stats import randint\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)\n\nRF = RandomForestClassifier(class_weight='balanced', random_state = 42)\n\nparam_dist = {\n 'n_estimators': randint(100, 300),\n    'max_depth': randint(5, 15),\n    'min_samples_split': randint(2, 10),\n    'min_samples_leaf': randint(1, 10),\n    'max_features': ['auto', 'sqrt', 'log2']    \n}\n\n\nrandom_search = RandomizedSearchCV(param_distributions = param_dist, \n                                   estimator = RF, cv = 3, n_iter=20,random_state=42,\n                                  scoring = 'recall')\n\nrandom_search.fit(X_train, y_train)\nbest_model = random_search.best_estimator_\ny_pred = best_model.predict(X_test)\nprint(\"accuracy for Random forest is \", accuracy_score(y_test, y_pred))\n\n# 2. Classification Report (includes precision, recall, F1-score for each class)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# 3. Confusion Matrix\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:17.595018Z","iopub.execute_input":"2025-07-26T22:21:17.595726Z","iopub.status.idle":"2025-07-26T22:21:38.334831Z","shell.execute_reply.started":"2025-07-26T22:21:17.595690Z","shell.execute_reply":"2025-07-26T22:21:38.333527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# XGBoost classifier with recall as (best)\nfrom xgboost import XGBClassifier\nfrom scipy.stats import uniform\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\nscale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\nXGBclassifier = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state = 42)\n\nparam_dist = {\n 'n_estimators': randint(100, 500),         \n    'max_depth': randint(3, 15),              \n    'learning_rate': uniform(0.01, 0.3),       \n    'subsample': uniform(0.6, 0.4),            \n    'colsample_bytree': uniform(0.6, 0.4),     \n    'gamma': uniform(0, 5),                   \n    'reg_alpha': uniform(0, 1),               \n    'reg_lambda': uniform(0, 1)   \n}\n\n\nrandom_search = RandomizedSearchCV(param_distributions = param_dist, \n                                   estimator = XGBclassifier, cv = 3, n_iter=20,random_state=42,\n                                  scoring = 'recall')\n\nrandom_search.fit(X_train, y_train)\nbest_model = random_search.best_estimator_\ny_pred = best_model.predict(X_test)\nprint(\"accuracy for XGBOOST is \", accuracy_score(y_test, y_pred))\n\n# 2. Classification Report (includes precision, recall, F1-score for each class)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# 3. Confusion Matrix\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:38.336060Z","iopub.execute_input":"2025-07-26T22:21:38.336386Z","iopub.status.idle":"2025-07-26T22:21:45.911299Z","shell.execute_reply.started":"2025-07-26T22:21:38.336359Z","shell.execute_reply":"2025-07-26T22:21:45.910479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# to further reduce false negatives - as  this is healthcare problem  ---> did not help","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:45.911973Z","iopub.execute_input":"2025-07-26T22:21:45.912803Z","iopub.status.idle":"2025-07-26T22:21:45.916963Z","shell.execute_reply.started":"2025-07-26T22:21:45.912779Z","shell.execute_reply":"2025-07-26T22:21:45.915904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nscale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n\nXGBclassifier = XGBClassifier(\n    scale_pos_weight=scale_pos_weight,\n    random_state=42,\n    use_label_encoder=False,\n    objective='binary:logistic'\n)\n\n# Random search\nrandom_search = RandomizedSearchCV(\n    estimator=XGBclassifier,\n    param_distributions=param_dist,\n    n_iter=20,\n    scoring='recall',\n    cv=3,\n    random_state=42,\n    verbose=1\n)\n\n# Fit with early stopping using **fit_params\nrandom_search.fit(\n    X_train,\n    y_train\n)\n\n# Best model\nbest_model = random_search.best_estimator_\nbest_model.fit(X_train, y_train,\n               eval_set=[(X_test, y_test)],\n               early_stopping_rounds=10,\n               eval_metric='aucpr',\n               verbose=False)\n\ny_pred = best_model.predict(X_test)\n\n# Results\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:21:45.917972Z","iopub.execute_input":"2025-07-26T22:21:45.918347Z","iopub.status.idle":"2025-07-26T22:21:53.793595Z","shell.execute_reply.started":"2025-07-26T22:21:45.918324Z","shell.execute_reply":"2025-07-26T22:21:53.792304Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# threshold tuning","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nf1_scores = []\nfor t in thresholds:\n    y_pred_thresh = (y_probs >= t).astype(int)\n    f1 = f1_score(y_test, y_pred_thresh)\n    f1_scores.append(f1)\n\nbest_thresh = thresholds[f1_scores.index(max(f1_scores))]\nprint(\"Best threshold for max F1:\", round(best_thresh, 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:27:31.544972Z","iopub.execute_input":"2025-07-26T22:27:31.545460Z","iopub.status.idle":"2025-07-26T22:27:31.564135Z","shell.execute_reply.started":"2025-07-26T22:27:31.545425Z","shell.execute_reply":"2025-07-26T22:27:31.562484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# XGBoost classifier with recall as (best)\nfrom xgboost import XGBClassifier\nfrom scipy.stats import uniform\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.3, random_state = 42)\nscale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\nXGBclassifier = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state = 42)\n\nparam_dist = {\n 'n_estimators': randint(100, 500),         \n    'max_depth': randint(3, 15),              \n    'learning_rate': uniform(0.01, 0.3),       \n    'subsample': uniform(0.6, 0.4),            \n    'colsample_bytree': uniform(0.6, 0.4),     \n    'gamma': uniform(0, 5),                   \n    'reg_alpha': uniform(0, 1),               \n    'reg_lambda': uniform(0, 1)   \n}\n\n\nrandom_search = RandomizedSearchCV(param_distributions = param_dist, \n                                   estimator = XGBclassifier, cv = 3, n_iter=20,random_state=42,\n                                  scoring = 'recall')\n\nrandom_search.fit(X_train, y_train)\nbest_model = random_search.best_estimator_\ny_probs = best_model.predict_proba(X_test)[:, 1]\n\nthreshold = 0.35\ny_pred_thresh = (y_probs >= threshold).astype(int)\n\n\nprint(\"Confusion Matrix at threshold =\", threshold)\nprint(confusion_matrix(y_test, y_pred_thresh))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred_thresh))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T22:26:01.844823Z","iopub.execute_input":"2025-07-26T22:26:01.845781Z","iopub.status.idle":"2025-07-26T22:26:12.375640Z","shell.execute_reply.started":"2025-07-26T22:26:01.845751Z","shell.execute_reply":"2025-07-26T22:26:12.374793Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Summary\nThis project uses the Pima Indians Diabetes dataset to build a robust machine learning pipeline that predicts the presence of diabetes based on diagnostic measurements. Given the medical context, the primary objective is to maximize recall for the positive class (patients with diabetes), minimizing false negatives to avoid missed diagnoses.\n\n**Key Highlights:**\nObjective: Binary classification to predict diabetes (0 = No, 1 = Yes)\n\nDataset: Pima Indians Diabetes Dataset (UCI / Kaggle)\n\nProblem Type: Imbalanced classification (class 1 ~35%)\n\nPrimary Metric: Recall (sensitivity) for class 1\n\n**Workflow & Techniques:**\n\nEDA & Preprocessing:\n\n* Handled outliers using IQR method\n* Replaced biologically implausible 0 values (e.g., insulin, skin thickness) via KNN imputation\n* Applied RobustScaler to handle skewed distributions\n* Stratified train-test split to preserve class balance\n\n\n**Modeling:**\n\n* Compared Random Forest, Logistic Regression, and XGBoost\n* Used scale_pos_weight in XGBoost to address imbalance\n* Performed RandomizedSearchCV with recall as scoring metric\n\n**Threshold Tuning:**\n\n* Selected threshold to maximize F1-score and recall without compromising precision significantly\n\n**Results:**\n\n* Metric\tValue (XGBoost with threshold tuning)\n* Accuracy\t~78%\n* Recall (Class 1)\t↑ > 80%\n* Precision (Class 1)\t~60%\n* Confusion Matrix\tIncluded in final notebook\n\n**Key Learnings:**\n\n* Class imbalance can be addressed with a combination of sampling strategies, custom loss weighting, and threshold optimization\n* In healthcare problems, recall is more critical than accuracy\n* Proper EDA, scaling, and imputation are essential for model stability and reliability\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}